{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set WORKDIR to the top of experiment repository\n",
    "%cd ..\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mlflow\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "import pandas as pd\n",
    "# from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "# import torch\n",
    "from src.settings import (\n",
    "    MLFLOW_TRACKING_USERNAME,\n",
    "    EXPERIMENT_NAME,\n",
    "    )\n",
    "\n",
    "\n",
    "def timestamp():\n",
    "    \"\"\"This function creates current timestamp\"\"\"\n",
    "    return datetime.now().strftime(\"%Y_%m_%d%H_%M_%S\")\n",
    "\n",
    "\n",
    "# select the model for evaluation\n",
    "all_models = {\n",
    "    'all-mpnet-base-v2': 'sentence-transformers/all-mpnet-base-v2',\n",
    "    'stsb-roberta-large': 'cross-encoder/stsb-roberta-large',\n",
    "    'stsb-roberta-base': 'cross-encoder/stsb-roberta-base',\n",
    "    'Legal-BERT': 'nlpaueb/legal-bert-base-uncased',\n",
    "    'EURLEX-BERT': 'nlpaueb/bert-base-uncased-eurlex',\n",
    "    'SciBERT': 'allenai/scibert_scivocab_uncased',\n",
    "}\n",
    "\n",
    "selected_model = all_models['stsb-roberta-base']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test dataset\n",
    "df_test = pd.read_parquet('data/test_clean.parquet')\n",
    "\n",
    "sentence_pairs = list(zip(df_test['text'].tolist(),df_test['text_b'].tolist()))\n",
    "sentence_pairs_lds = [{\"text\": x[0], \"text_pair\": x[1]} for x in sentence_pairs]\n",
    "\n",
    "labels_true = df_test['label'].tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence-Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "import torch\n",
    "\n",
    "# Load a pre-trained CrossEncoder model\n",
    "model = CrossEncoder(selected_model)\n",
    "\n",
    "# Predict scores for a pair of sentences\n",
    "scores = model.predict(sentence_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores to binary\n",
    "# threshold = 0.45\n",
    "for threshold in [\n",
    "    0.53,\n",
    "    0.66,\n",
    "    0.75,\n",
    "    0.85,\n",
    "    0.90,\n",
    "]:\n",
    "    labels_pred = [0 if x <= threshold else 1 for x in scores]\n",
    "    matthews_corrcoef_values = matthews_corrcoef(y_true=labels_true, y_pred=labels_pred)\n",
    "    print(matthews_corrcoef_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save score predictions\n",
    "# df_scores = pd.DataFrame(scores)\n",
    "# df_scores.to_parquet('data/stsb-roberta-base_pretrain_test_scores.parquet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HF Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "# import torch\n",
    "\n",
    "# # Load the tokenizer and model\n",
    "# tokenizer = AutoTokenizer.from_pretrained(selected_model)\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(selected_model)\n",
    "\n",
    "# scores = list()\n",
    "\n",
    "# for sentence_pair in sentence_pairs:\n",
    "#     # Example pair of legal texts\n",
    "#     text1 = sentence_pair[0]\n",
    "#     text2 = sentence_pair[1]\n",
    "\n",
    "#     # Tokenize the texts\n",
    "#     inputs = tokenizer(text1, text2, return_tensors='pt', truncation=True, padding=True)\n",
    "\n",
    "#     # Get model predictions\n",
    "#     outputs = model(**inputs)\n",
    "#     logits = outputs.logits\n",
    "\n",
    "#     # Get the score (e.g., similarity score)\n",
    "#     score = torch.softmax(logits, dim=1)\n",
    "\n",
    "#     scores.append(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "# import torch\n",
    "\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(selected_model)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(selected_model)\n",
    "\n",
    "# features = tokenizer(sentence_pairs, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     scores = model(**features).logits\n",
    "#     print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test_3 with pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import pipeline\n",
    "from transformers.pipelines.text_classification import ClassificationFunction\n",
    "import torch\n",
    "\n",
    "# Check if a GPU is available and set the device\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(selected_model)\n",
    "tokenizer = AutoTokenizer.from_pretrained(selected_model)\n",
    "\n",
    "pipe = pipeline(\"text-classification\", \n",
    "                model=model, \n",
    "                tokenizer=tokenizer, \n",
    "                padding=True, \n",
    "                truncation=True, \n",
    "                device=device, \n",
    "                function_to_apply=ClassificationFunction.SIGMOID,\n",
    "                )\n",
    "\n",
    "predictions = pipe(sentence_pairs_lds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binarization\n",
    "for threshold in [\n",
    "    0.53,\n",
    "    0.66,\n",
    "    0.75,\n",
    "    0.85,\n",
    "    0.90,\n",
    "]:\n",
    "    labels_pred = [0 if x['score'] <= threshold else 1 for x in predictions]\n",
    "    matthews_corrcoef_values = matthews_corrcoef(y_true=labels_true, y_pred=labels_pred)\n",
    "    print(matthews_corrcoef_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytor_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
