{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set WORKDIR to the top of experiment repository\n",
    "%cd ..\n",
    "# %pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from sklearn.metrics import matthews_corrcoef, f1_score\n",
    "from src.utils import timestamp\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import pipeline\n",
    "from transformers.pipelines.text_classification import ClassificationFunction\n",
    "import torch\n",
    "\n",
    "from src.settings import (\n",
    "    MLFLOW_EXPERIMENT_NAME,\n",
    "    )\n",
    "\n",
    "\n",
    "# Check if a GPU is available and set the device\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "# select the model for evaluation\n",
    "all_models = {\n",
    "    'all-mpnet-base-v2': 'sentence-transformers/all-mpnet-base-v2',\n",
    "    'stsb-roberta-large': 'cross-encoder/stsb-roberta-large',\n",
    "    'stsb-roberta-base': 'cross-encoder/stsb-roberta-base',\n",
    "    'Legal-BERT': 'nlpaueb/legal-bert-base-uncased',\n",
    "    'EURLEX-BERT': 'nlpaueb/bert-base-uncased-eurlex',\n",
    "    'SciBERT': 'allenai/scibert_scivocab_uncased',\n",
    "    # fine-tuned models below\n",
    "    'stsb-roberta-base_FT': 'saved_models/stsb-roberta-base_FT',\n",
    "    'stsb-roberta-large_FT': 'saved_models/stsb-roberta-large_FT',\n",
    "    'Legal-BERT_FT': 'saved_models/legal-bert-base-uncased_FT',\n",
    "}\n",
    "\n",
    "selected_model = all_models['stsb-roberta-large_FT']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test dataset\n",
    "dataset_path = 'data/test_clean.parquet'\n",
    "df_test = pd.read_parquet(dataset_path)\n",
    "\n",
    "# X\n",
    "sentence_pairs = list(zip(df_test['text'].tolist(),df_test['text_b'].tolist()))\n",
    "# sentence pairs as list of dicts for transformer's pipeline\n",
    "sentence_pairs_lods = [{\"text\": x[0], \"text_pair\": x[1]} for x in sentence_pairs]\n",
    "\n",
    "# y_true\n",
    "labels_true = df_test['label'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set num_labels for selected model - cross-encoder support only 1 label\n",
    "num_labels = 1 #1 if selected_model.split('/')[0] in ['cross-encoder'] else 2\n",
    "\n",
    "# load model and tokenizer\n",
    "model = AutoModelForSequenceClassification.from_pretrained(selected_model, num_labels=num_labels)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(selected_model)\n",
    "tokenizer = AutoTokenizer.from_pretrained(all_models['stsb-roberta-large'])\n",
    "\n",
    "# init mlflow experiment (use existing one)\n",
    "experiment = mlflow.get_experiment_by_name(MLFLOW_EXPERIMENT_NAME)\n",
    "\n",
    "# run experiment\n",
    "with mlflow.start_run(experiment_id=experiment.experiment_id, log_system_metrics=True) as run:\n",
    "    # set run name\n",
    "    mlflow.set_tag(key='mlflow.runName',\n",
    "                    value=f\"Test_{selected_model.split('/')[1]}_{timestamp()}\")\n",
    "    \n",
    "    # log parameters\n",
    "    mlflow.log_params({\n",
    "        'PyTorch Device': torch.cuda.get_device_name(torch.cuda.current_device()),\n",
    "        'Model': selected_model,\n",
    "        'Dataset': dataset_path,\n",
    "        'AutoModel Parameters': model,\n",
    "        'Tokenizer': tokenizer,\n",
    "    })\n",
    "\n",
    "    # run pipeline for model predictions\n",
    "    pipe = pipeline(\"text-classification\", \n",
    "                    model = model, \n",
    "                    tokenizer = tokenizer, \n",
    "                    padding = True, \n",
    "                    truncation = True,\n",
    "                    # max_length = 512, \n",
    "                    device = device, \n",
    "                    function_to_apply = ClassificationFunction.SIGMOID,\n",
    "                    top_k=1,  # return only top 1 predicted label with score\n",
    "                    )\n",
    "\n",
    "    predictions = pipe(sentence_pairs_lods)\n",
    "\n",
    "    threshold = 0.50\n",
    "    mlflow.log_metric(\"Threshold\", threshold)\n",
    "    labels_pred = [0 if x[0]['score'] <= threshold else 1 for x in predictions]\n",
    "\n",
    "    # # binarization for cross-encoders\n",
    "    # if selected_model.split('/')[0] in ['cross-encoder', 'saved_models']:\n",
    "    #     # for threshold in [\n",
    "    #     #     0.33,\n",
    "    #     #     0.53,\n",
    "    #     #     0.66,\n",
    "    #     #     0.75,\n",
    "    #     #     0.85,\n",
    "    #     # ]:\n",
    "    #     # threshold\n",
    "    #     threshold = 0.75\n",
    "    #     labels_pred = [0 if x[0]['score'] <= threshold else 1 for x in predictions]\n",
    "\n",
    "    # else:\n",
    "    #     # works with top_k=1 (returns only the most probable label with score) for transformer models\n",
    "    #     labels_pred = [0 if x[0]['label'] == 'LABEL_0' else 1 for x in predictions]\n",
    "\n",
    "    f1_score_value = f1_score(y_true=labels_true, y_pred=labels_pred, pos_label=1, average='binary')\n",
    "    mlflow.log_metric(\"F1 Score\", f1_score_value)\n",
    "\n",
    "    matthews_corrcoef_value = matthews_corrcoef(y_true=labels_true, y_pred=labels_pred)\n",
    "    mlflow.log_metric(\"Matthews Correlation Coefficient\", matthews_corrcoef_value)\n",
    "\n",
    "    print(f\"F1 Score: {f1_score_value}\\nMatthews Correlation Coefficient: {matthews_corrcoef_value}\")\n",
    "\n",
    "# end experiment\n",
    "mlflow.end_run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytor_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
