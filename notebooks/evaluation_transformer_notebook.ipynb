{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set WORKDIR to the top of experiment repository\n",
    "%cd ..\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from src.utils import timestamp\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import pipeline\n",
    "from transformers.pipelines.text_classification import ClassificationFunction\n",
    "import torch\n",
    "\n",
    "from src.settings import (\n",
    "    MLFLOW_TRACKING_USERNAME,\n",
    "    EXPERIMENT_NAME,\n",
    "    )\n",
    "\n",
    "\n",
    "# Check if a GPU is available and set the device\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "# select the model for evaluation\n",
    "all_models = {\n",
    "    'all-mpnet-base-v2': 'sentence-transformers/all-mpnet-base-v2',\n",
    "    'stsb-roberta-large': 'cross-encoder/stsb-roberta-large',\n",
    "    'stsb-roberta-base': 'cross-encoder/stsb-roberta-base',\n",
    "    'Legal-BERT': 'nlpaueb/legal-bert-base-uncased',\n",
    "    'EURLEX-BERT': 'nlpaueb/bert-base-uncased-eurlex',\n",
    "    'SciBERT': 'allenai/scibert_scivocab_uncased',\n",
    "}\n",
    "\n",
    "selected_model = all_models['stsb-roberta-base']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test dataset\n",
    "df_test = pd.read_parquet('data/test_clean.parquet')\n",
    "\n",
    "sentence_pairs = list(zip(df_test['text'].tolist(),df_test['text_b'].tolist()))\n",
    "labels_true = df_test['label'].tolist()\n",
    "\n",
    "# sentence pairs as list of dicts for transformer's pipeline\n",
    "sentence_pairs_lods = [{\"text\": x[0], \"text_pair\": x[1]} for x in sentence_pairs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(selected_model)\n",
    "tokenizer = AutoTokenizer.from_pretrained(selected_model)\n",
    "\n",
    "pipe = pipeline(\"text-classification\", \n",
    "                model = model, \n",
    "                tokenizer = tokenizer, \n",
    "                padding = True, \n",
    "                truncation = True,\n",
    "                # max_length = 512, \n",
    "                device = device, \n",
    "                function_to_apply = ClassificationFunction.SIGMOID,\n",
    "                )\n",
    "\n",
    "predictions = pipe(sentence_pairs_lods)\n",
    "\n",
    "# binarization\n",
    "for threshold in [\n",
    "    0.33,\n",
    "    0.53,\n",
    "    0.66,\n",
    "    0.75,\n",
    "    0.85,\n",
    "]:\n",
    "    labels_pred = [0 if x['score'] <= threshold else 1 for x in predictions]\n",
    "    matthews_corrcoef_values = matthews_corrcoef(y_true=labels_true, y_pred=labels_pred)\n",
    "    print(matthews_corrcoef_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'test_key': 'test_value',\n",
    "    'num_epochs': 5,\n",
    "}\n",
    "\n",
    "# init mlflow experiment (use existing one)\n",
    "experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "\n",
    "# run experiment\n",
    "with mlflow.start_run(experiment_id=experiment.experiment_id, log_system_metrics=True) as run:\n",
    "    # set run name\n",
    "    mlflow.set_tag(key='mlflow.runName',\n",
    "                    value=f'{selected_model.split('/')[1]}_{timestamp()}')\n",
    "    \n",
    "    # log parameters from config\n",
    "    mlflow.log_params(config)\n",
    "\n",
    "    \n",
    "    for epoch in range(config['num_epochs']):\n",
    "        # model.train()\n",
    "        mlflow.log_metric(\"random_metric\", epoch+random.randint(1, 100), step=epoch)\n",
    "\n",
    "# end experiment\n",
    "mlflow.end_run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- mlflow\n",
    "- Implement a classic transformer-based classifier.\n",
    "    - Split the training data into train and validation sets\n",
    "    - fine-tune\n",
    "    - test with test data\n",
    "- Obtain quality metrics on the test set. Do include F1 score and Matthews Correlation Coefficient https://scikit-learn.org/stable/modules/generated/sklearn.metrics.matthews_corrcoef.html\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytor_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
